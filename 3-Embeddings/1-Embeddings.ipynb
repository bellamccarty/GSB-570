{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb73af29-1b57-4bef-ae0d-044922277180",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Embeddings are integral to various natural language processing applications, with their quality crucial for optimal performance. They are commonly used in knowledge bases to represent textual data as dense vectors enabling efficient similarity search and retrieval. In Retrieval Augmented Generation (RAG), embeddings are used to retrieve relevant passages from a corpus to provide context for language models to generate informed, knowledge-grounded responses. Embeddings also play a key role in personalization and recommendation systems by representing user preferences, item characteristics, and historical interactions as vectors, allowing calculation of similarities for personalized recommendations based on user behavior and item embeddings. As new embedding models are released with incremental quality improvements, organizations must weigh the potential benefits against the associated costs of upgrading, considering factors like computational resources, data preprocessing, integration efforts, and projected performance gains impacting business metrics.\n",
    "\n",
    "#### How a piece of text is converted into a vector?\n",
    "Common approach is to use models which can provide contextualized embeddings for entire sentences. These models are based on deep learning architectures such as Transformers, which can capture the contextual information and relationships between words in a sentence more effectively.\n",
    "\n",
    "![Embedding Model](./images/vector_embedding.png)\n",
    "\n",
    "In addition to semantic search, you can use embeddings to augment your prompts for more accurate results through Retrieval Augmented Generation (RAG)—but in order to use them, you’ll need to store them in a database with vector capabilities.\n",
    "\n",
    "![Embedding Model](./images/vector_db.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347c523-adac-43c8-b651-acc6281afd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain_cohere -q\n",
    "%pip install spacy\n",
    "#%pip install python-dotenv -q\n",
    "#ignore error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d4086-c974-496a-99e1-2d5584e0755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you need to run this in a terminal window\n",
    "# python -m spacy download en_core_web_md\n",
    "# now restart your kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a4fed-79a7-4616-96b5-813c6f5bcc9a",
   "metadata": {},
   "source": [
    "Standard imports for the libraires we will be using in this notebook.  Try to keep your imports in the first cell so this can this code can more easliy be converted into a python program later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1513731f-ab9f-4e74-9249-e8ff08dfd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import traceback\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.embeddings import SpacyEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec844-3eee-4ce4-993d-d72ab9dd8560",
   "metadata": {},
   "source": [
    "## spaCy\n",
    "Lets define functions that will use various embedding models so we can generate vector embeddings and try to see the relationship between vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b6024-dda4-4dd3-836d-5830b472d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spacy_vector_embedding(text):\n",
    "    embedder = SpacyEmbeddings(model_name=\"en_core_web_md\")\n",
    "    query_embedding = embedder.embed_query(text)\n",
    "\n",
    "    return(np.array(query_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee761381-016d-4cbf-98a3-efdbd02c94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical formula for cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d0b14-4ee5-4d8c-b896-c324095f7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy\n",
    "king_vector = generate_spacy_vector_embedding(\"King\")\n",
    "queen_vector = generate_spacy_vector_embedding(\"Queen\")\n",
    "man_vector = generate_spacy_vector_embedding(\"man\")\n",
    "woman_vector = generate_spacy_vector_embedding(\"woman\")\n",
    "print(f\"This embedding has {len(king_vector)} dimensions\")\n",
    "print(king_vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39186dd6-e3bd-4368-8f13-75d1865e3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(man_vector, woman_vector)\n",
    "print(f\"Cosine Similarity distance man to woman: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance Spacey King to Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Spacey Queen vector and our King - man + woman: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da9dd5-f435-4cb9-b979-1ed18de5a4ec",
   "metadata": {},
   "source": [
    "So as we can see here, the relationships that are mathematically represented by these vectors can be used to relate these items in semantic space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010a53f-8b7c-441e-9318-5404be8197b6",
   "metadata": {},
   "source": [
    "### Now lets try some more models that have more features and see how that translates to different relationships\n",
    "Here is a helper class to allow us to use Amazon Titan text embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3def53b-7ff0-4f76-8d80-e980909d8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanEmbeddings(object):\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "    def __init__(self, model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=None, region_name='us-west-1'):\n",
    "        \n",
    "        if boto3_client:\n",
    "            self.bedrock_boto3 = boto3_client\n",
    "        else:\n",
    "            # self.bedrock_boto3 = boto3.client(service_name='bedrock-runtime')\n",
    "            self.bedrock_boto3 = boto3.client(\n",
    "                service_name='bedrock-runtime', \n",
    "                region_name=region_name, \n",
    "            )\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def __call__(self, text, dimensions, normalize=True):\n",
    "        \"\"\"\n",
    "        Returns Titan Embeddings\n",
    "\n",
    "        Args:\n",
    "            text (str): text to embed\n",
    "            dimensions (int): Number of output dimensions.\n",
    "            normalize (bool): Whether to return the normalized embedding or not.\n",
    "\n",
    "        Return:\n",
    "            List[float]: Embedding\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        body = json.dumps({\n",
    "            \"inputText\": text,\n",
    "            \"dimensions\": dimensions,\n",
    "            \"normalize\": normalize\n",
    "        })\n",
    "\n",
    "        response = self.bedrock_boto3.invoke_model(\n",
    "            body=body, modelId=self.model_id, accept=self.accept, contentType=self.content_type\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "\n",
    "        return response_body['embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a6e37-cbbb-4444-8f0c-a2f00c5836ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrock_client(assumed_role: Optional[str] = None, region: Optional[str] = 'us-west-2',runtime: Optional[bool] = True,external_id=None, ep_url=None):\n",
    "    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides \n",
    "    \"\"\"\n",
    "    target_region = region\n",
    "\n",
    "    #print(f\"Create new client\\n  Using region: {target_region}:external_id={external_id}: \")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        if external_id:\n",
    "            response = sts.assume_role(\n",
    "                RoleArn=str(assumed_role),\n",
    "                RoleSessionName=\"langchain-llm-1\",\n",
    "                ExternalId=external_id\n",
    "            )\n",
    "        else:\n",
    "            response = sts.assume_role(\n",
    "                RoleArn=str(assumed_role),\n",
    "                RoleSessionName=\"langchain-llm-1\",\n",
    "            )\n",
    "        print(f\"Using role: {assumed_role} ... sts::successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    if ep_url:\n",
    "        bedrock_client = session.client(service_name=service_name,config=retry_config,endpoint_url = ep_url, **client_kwargs )\n",
    "    else:\n",
    "        bedrock_client = session.client(service_name=service_name,config=retry_config, **client_kwargs )\n",
    "\n",
    "    #print(\"boto3 Bedrock client successfully created!\")\n",
    "    #print(bedrock_client._endpoint)\n",
    "    return bedrock_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579e61be-17f2-4edd-81ea-10a5ac462cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_titan_vector_embedding(text, embedding_size):\n",
    "    aws_client = get_bedrock_client()\n",
    "    bedrock_embeddings = TitanEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=aws_client)\n",
    "    \n",
    "    modelId = \"amazon.titan-embed-text-v2:0\"  # \n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    \n",
    "\n",
    "    model_input={\n",
    "        \"inputText\": text,\n",
    "        \"dimensions\": embedding_size,\n",
    "        \"normalize\": True\n",
    "    }\n",
    "    \n",
    "    body = json.dumps(model_input)\n",
    "    response = aws_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    embedding = response_body.get(\"embedding\")\n",
    "\n",
    "    return np.array(embedding)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbc44d-cd64-4c13-b21e-33b3af9f60cb",
   "metadata": {},
   "source": [
    "Now lets look at the same idea with Titan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56a80c-ad91-4b93-ab86-c8f0398b5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Titan\n",
    "king_vector = generate_titan_vector_embedding(\"King\", 1024)\n",
    "queen_vector = generate_titan_vector_embedding(\"Queen\", 1024)\n",
    "man_vector = generate_titan_vector_embedding(\"man\", 1024)\n",
    "woman_vector = generate_titan_vector_embedding(\"woman\", 1024)\n",
    "print(f\"This embedding has {len(king_vector)} dimensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855a4f8-48e5-4ff1-a2f1-cf090985fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(man_vector, woman_vector)\n",
    "print(f\"Cosine Similarity distance man to woman: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance Titan King to Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Titan Queen vector and our King - man + woman: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e3afb-0f48-46fe-8f53-b385c06476e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(man_vector, woman_vector)\n",
    "print(f\"Cosine Similarity distance man to woman: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance Titan King to Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Titan Queen vector and our King - man + woman: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35157a12-af69-4d79-8a9f-d7229eef4bec",
   "metadata": {},
   "source": [
    "### Cohere\n",
    "Let's look at one more model to see how it compares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0667bf3-01ef-4493-8cbc-744413c0d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send in an array size of one and only return the 0th element\n",
    "def generate_cohere_vector_embedding(text_data):\n",
    "    aws_client = get_bedrock_client()\n",
    "    input_type = \"clustering\"\n",
    "    truncate = \"NONE\" # optional\n",
    "    model_id = \"cohere.embed-english-v3\" # or \"cohere.embed-multilingual-v3\"\n",
    "    \n",
    "    # Create the JSON payload for the request\n",
    "    json_params = {\n",
    "            'texts': [text_data],\n",
    "            'truncate': truncate, \n",
    "            \"input_type\": input_type\n",
    "        }\n",
    "    json_body = json.dumps(json_params)\n",
    "    params = {'body': json_body, 'modelId': model_id,}\n",
    "    \n",
    "    # Invoke the model and print the response\n",
    "    result = aws_client.invoke_model(**params)\n",
    "    response = json.loads(result['body'].read().decode())\n",
    "    return(np.array(response['embeddings'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec8edc-da15-4f5b-8d5e-ad5af3576a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input cohere for embedding \n",
    "king_vector = generate_cohere_vector_embedding('King')\n",
    "queen_vector = generate_cohere_vector_embedding(\"Queen\")\n",
    "man_vector = generate_cohere_vector_embedding(\"man\")\n",
    "woman_vector = generate_cohere_vector_embedding(\"woman\")\n",
    "print(f\"This embedding has {len(king_vector)} dimensions\")\n",
    "print(king_vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a6dca-a476-468e-ac44-dbef8f363899",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(man_vector, woman_vector)\n",
    "print(f\"Cosine Similarity distance man to woman: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance Cohere King to Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Cohere Queen vector and our King - man + woman: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853152e-aee5-4ebd-9496-13310f6eab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spacy\n",
    "king_vector = generate_spacy_vector_embedding(\"King\")\n",
    "queen_vector = generate_spacy_vector_embedding(\"Queen\")\n",
    "man_vector = generate_spacy_vector_embedding(\"man\")\n",
    "woman_vector = generate_spacy_vector_embedding(\"woman\")\n",
    "print(f\"This embedding has {len(king_vector)} dimensions\")\n",
    "print(king_vector[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55107547-7270-4c72-8a1f-1afc4f6d7d40",
   "metadata": {},
   "source": [
    "Let's examine other phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8306f-e557-4fe6-af63-8f73c6b4c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(\"cat\", 1024), generate_titan_vector_embedding(\"book\", 1024))\n",
    "print(f\"Cosine Similarity of cat to book using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb5e7e-726f-4054-bf8e-760e4b9fa440",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(\"cat\"), generate_cohere_vector_embedding(\"book\"))\n",
    "print(f\"Cosine Similarity of cat to book using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362cdf3-c640-4628-82cb-688c4d631998",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_spacy_vector_embedding(\"cat\"), generate_spacy_vector_embedding(\"book\"))\n",
    "print(f\"Cosine Similarity of cat to book using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aaa723-3154-4336-8d3e-35d83d117d7b",
   "metadata": {},
   "source": [
    "Now let's look at a larger sentences and see how larger models with more complexity handle the same task Here are 2 sentences that semantically similar but use different words and phrasing.\n",
    "\n",
    "The majestic, towering skyscrapers, their gleaming windows reflecting the golden rays of the setting sun, stood as a testament to human ingenuity and the indomitable spirit of progress, while the bustling streets below teemed with life as people from all walks of life hurried to their destinations, their faces a mix of determination and weariness, yet each individual contributing to the vibrant tapestry of the city's existence.\n",
    "\n",
    "The awe-inspiring, colossal high-rises, their polished glass facades mirroring the warm, amber glow of the fading daylight, served as a powerful symbol of human innovation and the unyielding drive for advancement, as the lively thoroughfares beneath pulsed with energy, filled with individuals from diverse backgrounds rushing to their intended locations, their expressions an amalgamation of resolve and fatigue, yet all playing a vital role in the dynamic, intricate mosaic that shaped the city's vibrant identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb721f75-5bae-4da9-8344-e5811c2f31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"The majestic, towering skyscrapers, their gleaming windows reflecting the golden rays of the setting sun, stood as a testament to human ingenuity and the indomitable spirit of progress, while the bustling streets below teemed with life as people from all walks of life hurried to their destinations, their faces a mix of determination and weariness, yet each individual contributing to the vibrant tapestry of the city's existence.\"\n",
    "sentence2 = \"The awe-inspiring, colossal high-rises, their polished glass facades mirroring the warm, amber glow of the fading daylight, served as a powerful symbol of human innovation and the unyielding drive for advancement, as the lively thoroughfares beneath pulsed with energy, filled with individuals from diverse backgrounds rushing to their intended locations, their expressions an amalgamation of resolve and fatigue, yet all playing a vital role in the dynamic, intricate mosaic that shaped the city's vibrant identity.\"\n",
    "similarity = cosine_similarity(generate_spacy_vector_embedding(sentence1), generate_spacy_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86acf2c4-bc8a-49d4-9ea4-5488a96c93aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(sentence1, 1024), generate_titan_vector_embedding(sentence2, 1024))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131bfda-1db4-4b29-b184-0c0bdc03779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(sentence1), generate_cohere_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6923237-fc59-45d1-b573-d0aa2b29c3ec",
   "metadata": {},
   "source": [
    "#### Snowboarding\n",
    "Snowboarding on fresh powder is pure freedom—like floating, flying, and dancing all at once. The moment your board hits untouched snow, everything changes. It’s soft, silent, and surreal. Instead of the usual hardpack chatter under your feet, there’s this quiet swoosh as you carve through the fluff. Each turn feels like slicing through silk. Your board sinks just a little, giving you that surfy, weightless feeling, like you're gliding above the ground. You lean back slightly to stay afloat, and with each movement, you’re not just riding the mountain—you’re flowing with it. The powder cushions every bump and fall, making the ride forgiving and playful. The world around you goes quiet—muffled by the snow—so all you hear is the wind in your ears and the sound of your own breath. Trees blur past, sunlight catches on snowflakes in the air, and your legs start to burn as you float turn after turn, not wanting it to end. It’s the kind of ride that leaves your heart pounding and your face aching from grinning so hard. The first tracks you lay through fresh powder? They’re yours alone—like signing your name on nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20e933-e6fb-4205-9280-fb92fbeb1faa",
   "metadata": {},
   "source": [
    "#### Surfing \n",
    "Surfing is an experience that blends adrenaline, tranquility, and connection with nature in a way that's hard to put into words but unforgettable once you feel it. Imagine paddling out through the rhythm of the ocean, the sun warming your back, saltwater clinging to your skin. You wait just beyond the breakers, scanning the horizon for the right wave—a moment of stillness, of anticipation. When it comes, you turn your board toward shore, paddle hard, and feel the lift as the wave catches you. Then you pop up—feet planted, knees bent, arms out—and suddenly, you’re riding a force of nature. The board glides effortlessly as the wave curls behind you. There's a split second where everything aligns: your balance, the speed, the sound of rushing water, and the pure exhilaration of being carried by the ocean. Every ride is different. Some are smooth and easy, others fast and wild. Sometimes you wipe out—tossed and tumbled underwater, lungs burning, trying to find the surface. But even that feels part of the magic. It’s humbling. It teaches respect. Surfing isn't just a sport. It’s a state of mind. It’s patience and persistence. It’s the joy of catching your first wave or the meditative calm of floating on your board, just watching the sun dip below the horizon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077766d-8d7b-47a1-a816-6c9b2906ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfing = \"Surfing is an experience that blends adrenaline, tranquility, and connection with nature in a way that's hard to put into words but unforgettable once you feel it. Imagine paddling out through the rhythm of the ocean, the sun warming your back, saltwater clinging to your skin. You wait just beyond the breakers, scanning the horizon for the right wave—a moment of stillness, of anticipation. When it comes, you turn your board toward shore, paddle hard, and feel the lift as the wave catches you. Then you pop up—feet planted, knees bent, arms out—and suddenly, you’re riding a force of nature. The board glides effortlessly as the wave curls behind you. There's a split second where everything aligns: your balance, the speed, the sound of rushing water, and the pure exhilaration of being carried by the ocean. Every ride is different. Some are smooth and easy, others fast and wild. Sometimes you wipe out—tossed and tumbled underwater, lungs burning, trying to find the surface. But even that feels part of the magic. It’s humbling. It teaches respect. Surfing isn't just a sport. It’s a state of mind. It’s patience and persistence. It’s the joy of catching your first wave or the meditative calm of floating on your board, just watching the sun dip below the horizon.\"\n",
    "snowboading = \"Snowboarding on fresh powder is pure freedom—like floating, flying, and dancing all at once. The moment your board hits untouched snow, everything changes. It’s soft, silent, and surreal. Instead of the usual hardpack chatter under your feet, there’s this quiet swoosh as you carve through the fluff. Each turn feels like slicing through silk. Your board sinks just a little, giving you that surfy, weightless feeling, like you're gliding above the ground. You lean back slightly to stay afloat, and with each movement, you’re not just riding the mountain—you’re flowing with it. The powder cushions every bump and fall, making the ride forgiving and playful. The world around you goes quiet—muffled by the snow—so all you hear is the wind in your ears and the sound of your own breath. Trees blur past, sunlight catches on snowflakes in the air, and your legs start to burn as you float turn after turn, not wanting it to end. It’s the kind of ride that leaves your heart pounding and your face aching from grinning so hard. The first tracks you lay through fresh powder? They’re yours alone—like signing your name on nature.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1c6d7-4459-4698-948f-ae684363b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(surfing, 1024), generate_titan_vector_embedding(snowboading, 1024))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e93a8e-ff31-4508-ba72-01c838b462fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_spacy_vector_embedding(surfing), generate_spacy_vector_embedding(snowboading))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42a2dc-b367-4720-a755-baf1e5381b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(surfing), generate_cohere_vector_embedding(snowboading))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85e210-24cf-4f7d-9df8-f13f414ded7c",
   "metadata": {},
   "source": [
    "#### Random\n",
    "Okay let's try something random and see what the similarity looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628dee7-e493-4996-8501-173cf5477220",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1= \"The giraffe wore a monocle while arguing with a squirrel about the ethics of pancake toppings.\"\n",
    "sentence2=\"A forgotten shoelace fluttered quietly on a moonlit battlefield, untouched by time or tennis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc37e034-4559-41c2-9cca-58feca7eb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_spacy_vector_embedding(sentence1), generate_spacy_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065178a8-a950-45e1-ac33-90ec17de76d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(sentence1, 1024), generate_titan_vector_embedding(sentence2, 1024))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5dbdc-0104-430d-98e9-3981d9a7fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(sentence1), generate_cohere_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c580d1-09fb-4715-9db6-d3b20533aa06",
   "metadata": {},
   "source": [
    "#### And the winner is?\n",
    "I guess it depends on what you are tryiing to accomplish.  You need to sample different embedding models based on your use case.\n",
    "Here is the [Huggingface MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c7c50-b62c-41a1-9c73-b35bbe761140",
   "metadata": {},
   "source": [
    "#### Embeddings work on images as well\n",
    "Let's compare different images together using an image embedding model.  There are many well known image embedding models here are a few:\n",
    "ResNet (e.g., ResNet-50, ResNet-101)\n",
    "-Deep residual networks\n",
    "-Common for feature extraction\n",
    "-Embeddings: vectors from the penultimate (before-softmax) layer\n",
    "VGG (VGG16, VGG19)\n",
    "-Simpler architecture\n",
    "-Good for smaller-scale tasks or transfer learning\n",
    "-Inception (GoogLeNet, Inception-v3)\n",
    "-Multi-scale filters\n",
    "-Good trade-off between speed and accuracy\n",
    "EfficientNet\n",
    "-Very efficient, scalable architecture\n",
    "-Great for resource-constrained environments\n",
    "\n",
    "Using EfficientNet let's try comparing the following images\n",
    "\n",
    "![House Sparrow](./images/sparrow-sm.jpg) ![Black Phoebe](./images/phoebe-sm.jpg) ![White Crown Sparrow](./images/whitecrown-sm.jpg)![Fork](./images/fork-sm.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fffc023-70c7-443d-aec5-57657f7e9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load EfficientNet (without the classifier head)\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model.classifier = torch.nn.Identity()  # Remove the final classification layer\n",
    "model.eval()\n",
    "\n",
    "# Preprocessing pipeline to match EfficientNet's input requirements\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
    "        std=[0.229, 0.224, 0.225]    # ImageNet std\n",
    "    )\n",
    "])\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_tensor)\n",
    "    return embedding.squeeze()  # Remove batch dimension\n",
    "\n",
    "def cosine_similarity(tensor1, tensor2):\n",
    "    return F.cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94312b-e395-4677-9b58-57ddd4812ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call EfficientNet on all sample images\n",
    "fork_image_emb = get_image_embedding('./images/fork.jpg')\n",
    "sparrow_image_emb = get_image_embedding('./images/sparrow.jpg')\n",
    "phoebe_image_emb = get_image_embedding('./images/phoebe.jpg')\n",
    "white_crown_image_emb = get_image_embedding('./images/whitecrown.jpg')\n",
    "\n",
    "similarity = cosine_similarity(sparrow_image_emb, phoebe_image_emb)\n",
    "print(f\"Cosine similarity between two different birds: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(sparrow_image_emb, fork_image_emb)\n",
    "print(f\"Cosine similarity between the fork and the sparrow: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(sparrow_image_emb, white_crown_image_emb)\n",
    "print(f\"Cosine similarity between the white crown sparrow and house sparrow: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104dcc74-4ae3-4d89-9f63-aceac24f637c",
   "metadata": {},
   "source": [
    "#### Assignment\n",
    "Go find some data that you think will be usefull for your project and try a few embedding models that you think mght work well for your use case.  After you manually separate the data into a few samples, show how the embedding model you choose will do a good job comaring relavancy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
