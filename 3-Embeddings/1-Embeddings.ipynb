{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb73af29-1b57-4bef-ae0d-044922277180",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Embeddings\n",
    "\n",
    "Embeddings are integral to various natural language processing applications, with their quality crucial for optimal performance. They are commonly used in knowledge bases to represent textual data as dense vectors enabling efficient similarity search and retrieval. In Retrieval Augmented Generation (RAG), embeddings are used to retrieve relevant passages from a corpus to provide context for language models to generate informed, knowledge-grounded responses. Embeddings also play a key role in personalization and recommendation systems by representing user preferences, item characteristics, and historical interactions as vectors, allowing calculation of similarities for personalized recommendations based on user behavior and item embeddings. As new embedding models are released with incremental quality improvements, organizations must weigh the potential benefits against the associated costs of upgrading, considering factors like computational resources, data preprocessing, integration efforts, and projected performance gains impacting business metrics.\n",
    "\n",
    "#### How a piece of text is converted into a vector?\n",
    "Common approach is to use models which can provide contextualized embeddings for entire sentences. These models are based on deep learning architectures such as Transformers, which can capture the contextual information and relationships between words in a sentence more effectively.\n",
    "\n",
    "![Embedding Model](./images/vector_embedding.png)\n",
    "\n",
    "In addition to semantic search, you can use embeddings to augment your prompts for more accurate results through Retrieval Augmented Generation (RAG)—but in order to use them, you’ll need to store them in a database with vector capabilities.\n",
    "\n",
    "![Embedding Model](./images/vector_db.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7347c523-adac-43c8-b651-acc6281afd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.11/site-packages (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (8.3.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy) (75.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.4.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: cloudpickle>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from srsly<3.0.0,>=2.4.3->spacy) (3.1.1)\n",
      "Requirement already satisfied: ujson>=1.35 in /opt/conda/lib/python3.11/site-packages (from srsly<3.0.0,>=2.4.3->spacy) (5.10.0)\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install langchain_cohere -q\n",
    "%pip install spacy\n",
    "#%pip install python-dotenv -q\n",
    "#ignore error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13d4086-c974-496a-99e1-2d5584e0755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you need to run this in a terminal window\n",
    "# python -m spacy download en_core_web_md\n",
    "# now restart your kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a4fed-79a7-4616-96b5-813c6f5bcc9a",
   "metadata": {},
   "source": [
    "Standard imports for the libraires we will be using in this notebook.  Try to keep your imports in the first cell so this can this code can more easliy be converted into a python program later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1513731f-ab9f-4e74-9249-e8ff08dfd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import traceback\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.embeddings import SpacyEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec844-3eee-4ce4-993d-d72ab9dd8560",
   "metadata": {},
   "source": [
    "## spaCy\n",
    "Lets define functions that will use various embedding models so we can generate vector embeddings and try to see the relationship between vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1b6024-dda4-4dd3-836d-5830b472d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spacy_vector_embedding(text):\n",
    "    embedder = SpacyEmbeddings(model_name=\"en_core_web_md\")\n",
    "    query_embedding = embedder.embed_query(text)\n",
    "\n",
    "    return(np.array(query_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee761381-016d-4cbf-98a3-efdbd02c94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical formula for cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0d0b14-4ee5-4d8c-b896-c324095f7b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This embedding has 300 dimensions\n",
      "[-0.60644001 -0.51204997  0.0064921  -0.29194    -0.56515002]\n"
     ]
    }
   ],
   "source": [
    "#Spacy\n",
    "king_vector = generate_spacy_vector_embedding(\"King\")\n",
    "queen_vector = generate_spacy_vector_embedding(\"Queen\")\n",
    "man_vector = generate_spacy_vector_embedding(\"man\")\n",
    "woman_vector = generate_spacy_vector_embedding(\"woman\")\n",
    "print(f\"This embedding has {len(king_vector)} dimensions\")\n",
    "print(king_vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39186dd6-e3bd-4368-8f13-75d1865e3928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity distance man to woman: 0.1561\n",
      "Cosine Similarity distance Spacey King to Queen: 0.3825\n",
      "Cosine Similarity distance between Spacey Queen vector and our King - man + woman: 0.4812\n"
     ]
    }
   ],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(man_vector, woman_vector)\n",
    "print(f\"Cosine Similarity distance man to woman: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance Spacey King to Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Spacey Queen vector and our King - man + woman: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da9dd5-f435-4cb9-b979-1ed18de5a4ec",
   "metadata": {},
   "source": [
    "So as we can see here, the relationships that are mathematically represented by these vectors can be used to relate these items in semantic space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3010a53f-8b7c-441e-9318-5404be8197b6",
   "metadata": {},
   "source": [
    "### Now lets try some more models that have more features and see how that translates to different relationships\n",
    "Here is a helper class to allow us to use Amazon Titan text embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3def53b-7ff0-4f76-8d80-e980909d8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanEmbeddings(object):\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "    \n",
    "    def __init__(self, model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=None, region_name='us-west-1'):\n",
    "        \n",
    "        if boto3_client:\n",
    "            self.bedrock_boto3 = boto3_client\n",
    "        else:\n",
    "            # self.bedrock_boto3 = boto3.client(service_name='bedrock-runtime')\n",
    "            self.bedrock_boto3 = boto3.client(\n",
    "                service_name='bedrock-runtime', \n",
    "                region_name=region_name, \n",
    "            )\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def __call__(self, text, dimensions, normalize=True):\n",
    "        \"\"\"\n",
    "        Returns Titan Embeddings\n",
    "\n",
    "        Args:\n",
    "            text (str): text to embed\n",
    "            dimensions (int): Number of output dimensions.\n",
    "            normalize (bool): Whether to return the normalized embedding or not.\n",
    "\n",
    "        Return:\n",
    "            List[float]: Embedding\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        body = json.dumps({\n",
    "            \"inputText\": text,\n",
    "            \"dimensions\": dimensions,\n",
    "            \"normalize\": normalize\n",
    "        })\n",
    "\n",
    "        response = self.bedrock_boto3.invoke_model(\n",
    "            body=body, modelId=self.model_id, accept=self.accept, contentType=self.content_type\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "\n",
    "        return response_body['embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a51a6e37-cbbb-4444-8f0c-a2f00c5836ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bedrock_client(assumed_role: Optional[str] = None, region: Optional[str] = 'us-west-2',runtime: Optional[bool] = True,external_id=None, ep_url=None):\n",
    "    \"\"\"Create a boto3 client for Amazon Bedrock, with optional configuration overrides \n",
    "    \"\"\"\n",
    "    target_region = region\n",
    "\n",
    "    #print(f\"Create new client\\n  Using region: {target_region}:external_id={external_id}: \")\n",
    "    session_kwargs = {\"region_name\": target_region}\n",
    "    client_kwargs = {**session_kwargs}\n",
    "\n",
    "    profile_name = os.environ.get(\"AWS_PROFILE\")\n",
    "    if profile_name:\n",
    "        print(f\"  Using profile: {profile_name}\")\n",
    "        session_kwargs[\"profile_name\"] = profile_name\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=target_region,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "    session = boto3.Session(**session_kwargs)\n",
    "\n",
    "    if assumed_role:\n",
    "        print(f\"  Using role: {assumed_role}\", end='')\n",
    "        sts = session.client(\"sts\")\n",
    "        if external_id:\n",
    "            response = sts.assume_role(\n",
    "                RoleArn=str(assumed_role),\n",
    "                RoleSessionName=\"langchain-llm-1\",\n",
    "                ExternalId=external_id\n",
    "            )\n",
    "        else:\n",
    "            response = sts.assume_role(\n",
    "                RoleArn=str(assumed_role),\n",
    "                RoleSessionName=\"langchain-llm-1\",\n",
    "            )\n",
    "        print(f\"Using role: {assumed_role} ... sts::successful!\")\n",
    "        client_kwargs[\"aws_access_key_id\"] = response[\"Credentials\"][\"AccessKeyId\"]\n",
    "        client_kwargs[\"aws_secret_access_key\"] = response[\"Credentials\"][\"SecretAccessKey\"]\n",
    "        client_kwargs[\"aws_session_token\"] = response[\"Credentials\"][\"SessionToken\"]\n",
    "\n",
    "    if runtime:\n",
    "        service_name='bedrock-runtime'\n",
    "    else:\n",
    "        service_name='bedrock'\n",
    "\n",
    "    if ep_url:\n",
    "        bedrock_client = session.client(service_name=service_name,config=retry_config,endpoint_url = ep_url, **client_kwargs )\n",
    "    else:\n",
    "        bedrock_client = session.client(service_name=service_name,config=retry_config, **client_kwargs )\n",
    "\n",
    "    #print(\"boto3 Bedrock client successfully created!\")\n",
    "    #print(bedrock_client._endpoint)\n",
    "    return bedrock_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "579e61be-17f2-4edd-81ea-10a5ac462cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_titan_vector_embedding(text, embedding_size):\n",
    "    aws_client = get_bedrock_client()\n",
    "    bedrock_embeddings = TitanEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", boto3_client=aws_client)\n",
    "    \n",
    "    modelId = \"amazon.titan-embed-text-v2:0\"  # \n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    \n",
    "\n",
    "    model_input={\n",
    "        \"inputText\": text,\n",
    "        \"dimensions\": embedding_size,\n",
    "        \"normalize\": True\n",
    "    }\n",
    "    \n",
    "    body = json.dumps(model_input)\n",
    "    response = aws_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    embedding = response_body.get(\"embedding\")\n",
    "\n",
    "    return np.array(embedding)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbc44d-cd64-4c13-b21e-33b3af9f60cb",
   "metadata": {},
   "source": [
    "Now lets look at the same idea with Titan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e56a80c-ad91-4b93-ab86-c8f0398b5840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This embedding has 1024 dimensions\n"
     ]
    }
   ],
   "source": [
    "#Titan\n",
    "king_vector = generate_titan_vector_embedding(\"King\", 1024)\n",
    "queen_vector = generate_titan_vector_embedding(\"Queen\", 1024)\n",
    "man_vector = generate_titan_vector_embedding(\"man\", 1024)\n",
    "woman_vector = generate_titan_vector_embedding(\"woman\", 1024)\n",
    "print(f\"This embedding has {len(king_vector)} dimensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5855a4f8-48e5-4ff1-a2f1-cf090985fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity distance man to woman: 0.4740\n",
      "Cosine Similarity distance Titan King to Queen: 0.4979\n",
      "Cosine Similarity distance between Titan Queen vector and our King - man + woman: 0.3938\n"
     ]
    }
   ],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(man_vector, woman_vector)\n",
    "print(f\"Cosine Similarity distance man to woman: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance Titan King to Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Titan Queen vector and our King - man + woman: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2e3afb-0f48-46fe-8f53-b385c06476e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity distance man to woman: 0.4740\n",
      "Cosine Similarity distance Titan King to Queen: 0.4979\n",
      "Cosine Similarity distance between Titan Queen vector and our King - man + woman: 0.3938\n"
     ]
    }
   ],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(man_vector, woman_vector)\n",
    "print(f\"Cosine Similarity distance man to woman: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance Titan King to Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Titan Queen vector and our King - man + woman: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35157a12-af69-4d79-8a9f-d7229eef4bec",
   "metadata": {},
   "source": [
    "### Cohere\n",
    "Let's look at one more model to see how it compares "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0667bf3-01ef-4493-8cbc-744413c0d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send in an array size of one and only return the 0th element\n",
    "def generate_cohere_vector_embedding(text_data):\n",
    "    aws_client = get_bedrock_client()\n",
    "    input_type = \"clustering\"\n",
    "    truncate = \"NONE\" # optional\n",
    "    model_id = \"cohere.embed-english-v3\" # or \"cohere.embed-multilingual-v3\"\n",
    "    \n",
    "    # Create the JSON payload for the request\n",
    "    json_params = {\n",
    "            'texts': [text_data],\n",
    "            'truncate': truncate, \n",
    "            \"input_type\": input_type\n",
    "        }\n",
    "    json_body = json.dumps(json_params)\n",
    "    params = {'body': json_body, 'modelId': model_id,}\n",
    "    \n",
    "    # Invoke the model and print the response\n",
    "    result = aws_client.invoke_model(**params)\n",
    "    response = json.loads(result['body'].read().decode())\n",
    "    return(np.array(response['embeddings'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faec8edc-da15-4f5b-8d5e-ad5af3576a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This embedding has 1024 dimensions\n",
      "[ 0.02383423 -0.0247345   0.02523804 -0.03985596 -0.06323242]\n"
     ]
    }
   ],
   "source": [
    "# Input cohere for embedding \n",
    "king_vector = generate_cohere_vector_embedding('King')\n",
    "queen_vector = generate_cohere_vector_embedding(\"Queen\")\n",
    "man_vector = generate_cohere_vector_embedding(\"man\")\n",
    "woman_vector = generate_cohere_vector_embedding(\"woman\")\n",
    "print(f\"This embedding has {len(king_vector)} dimensions\")\n",
    "print(king_vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b4a6dca-a476-468e-ac44-dbef8f363899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity distance man to woman: 0.7088\n",
      "Cosine Similarity distance Cohere King to Queen: 0.7343\n",
      "Cosine Similarity distance between Cohere Queen vector and our King - man + woman: 0.7225\n"
     ]
    }
   ],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(man_vector, woman_vector)\n",
    "print(f\"Cosine Similarity distance man to woman: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance Cohere King to Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Cohere Queen vector and our King - man + woman: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5853152e-aee5-4ebd-9496-13310f6eab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This embedding has 300 dimensions\n",
      "[-0.60644001 -0.51204997  0.0064921  -0.29194    -0.56515002]\n"
     ]
    }
   ],
   "source": [
    "#Spacy\n",
    "king_vector = generate_spacy_vector_embedding(\"King\")\n",
    "queen_vector = generate_spacy_vector_embedding(\"Queen\")\n",
    "man_vector = generate_spacy_vector_embedding(\"man\")\n",
    "woman_vector = generate_spacy_vector_embedding(\"woman\")\n",
    "print(f\"This embedding has {len(king_vector)} dimensions\")\n",
    "print(king_vector[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55107547-7270-4c72-8a1f-1afc4f6d7d40",
   "metadata": {},
   "source": [
    "Let's examine other phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4f8306f-e557-4fe6-af63-8f73c6b4c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of cat to book using Titan: 0.3219\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(\"cat\", 1024), generate_titan_vector_embedding(\"book\", 1024))\n",
    "print(f\"Cosine Similarity of cat to book using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9acb5e7e-726f-4054-bf8e-760e4b9fa440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of cat to book using Cohere: 0.5562\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(\"cat\"), generate_cohere_vector_embedding(\"book\"))\n",
    "print(f\"Cosine Similarity of cat to book using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4362cdf3-c640-4628-82cb-688c4d631998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of cat to book using Spacey: 0.0693\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_spacy_vector_embedding(\"cat\"), generate_spacy_vector_embedding(\"book\"))\n",
    "print(f\"Cosine Similarity of cat to book using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aaa723-3154-4336-8d3e-35d83d117d7b",
   "metadata": {},
   "source": [
    "Now let's look at a larger sentences and see how larger models with more complexity handle the same task Here are 2 sentences that semantically similar but use different words and phrasing.\n",
    "\n",
    "The majestic, towering skyscrapers, their gleaming windows reflecting the golden rays of the setting sun, stood as a testament to human ingenuity and the indomitable spirit of progress, while the bustling streets below teemed with life as people from all walks of life hurried to their destinations, their faces a mix of determination and weariness, yet each individual contributing to the vibrant tapestry of the city's existence.\n",
    "\n",
    "The awe-inspiring, colossal high-rises, their polished glass facades mirroring the warm, amber glow of the fading daylight, served as a powerful symbol of human innovation and the unyielding drive for advancement, as the lively thoroughfares beneath pulsed with energy, filled with individuals from diverse backgrounds rushing to their intended locations, their expressions an amalgamation of resolve and fatigue, yet all playing a vital role in the dynamic, intricate mosaic that shaped the city's vibrant identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb721f75-5bae-4da9-8344-e5811c2f31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Spacey: 0.9637\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"The majestic, towering skyscrapers, their gleaming windows reflecting the golden rays of the setting sun, stood as a testament to human ingenuity and the indomitable spirit of progress, while the bustling streets below teemed with life as people from all walks of life hurried to their destinations, their faces a mix of determination and weariness, yet each individual contributing to the vibrant tapestry of the city's existence.\"\n",
    "sentence2 = \"The awe-inspiring, colossal high-rises, their polished glass facades mirroring the warm, amber glow of the fading daylight, served as a powerful symbol of human innovation and the unyielding drive for advancement, as the lively thoroughfares beneath pulsed with energy, filled with individuals from diverse backgrounds rushing to their intended locations, their expressions an amalgamation of resolve and fatigue, yet all playing a vital role in the dynamic, intricate mosaic that shaped the city's vibrant identity.\"\n",
    "similarity = cosine_similarity(generate_spacy_vector_embedding(sentence1), generate_spacy_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86acf2c4-bc8a-49d4-9ea4-5488a96c93aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Titan: 0.7235\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(sentence1, 1024), generate_titan_vector_embedding(sentence2, 1024))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4131bfda-1db4-4b29-b184-0c0bdc03779e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Cohere: 0.8160\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(sentence1), generate_cohere_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6923237-fc59-45d1-b573-d0aa2b29c3ec",
   "metadata": {},
   "source": [
    "#### Snowboarding\n",
    "Snowboarding on fresh powder is pure freedom—like floating, flying, and dancing all at once. The moment your board hits untouched snow, everything changes. It’s soft, silent, and surreal. Instead of the usual hardpack chatter under your feet, there’s this quiet swoosh as you carve through the fluff. Each turn feels like slicing through silk. Your board sinks just a little, giving you that surfy, weightless feeling, like you're gliding above the ground. You lean back slightly to stay afloat, and with each movement, you’re not just riding the mountain—you’re flowing with it. The powder cushions every bump and fall, making the ride forgiving and playful. The world around you goes quiet—muffled by the snow—so all you hear is the wind in your ears and the sound of your own breath. Trees blur past, sunlight catches on snowflakes in the air, and your legs start to burn as you float turn after turn, not wanting it to end. It’s the kind of ride that leaves your heart pounding and your face aching from grinning so hard. The first tracks you lay through fresh powder? They’re yours alone—like signing your name on nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20e933-e6fb-4205-9280-fb92fbeb1faa",
   "metadata": {},
   "source": [
    "#### Surfing \n",
    "Surfing is an experience that blends adrenaline, tranquility, and connection with nature in a way that's hard to put into words but unforgettable once you feel it. Imagine paddling out through the rhythm of the ocean, the sun warming your back, saltwater clinging to your skin. You wait just beyond the breakers, scanning the horizon for the right wave—a moment of stillness, of anticipation. When it comes, you turn your board toward shore, paddle hard, and feel the lift as the wave catches you. Then you pop up—feet planted, knees bent, arms out—and suddenly, you’re riding a force of nature. The board glides effortlessly as the wave curls behind you. There's a split second where everything aligns: your balance, the speed, the sound of rushing water, and the pure exhilaration of being carried by the ocean. Every ride is different. Some are smooth and easy, others fast and wild. Sometimes you wipe out—tossed and tumbled underwater, lungs burning, trying to find the surface. But even that feels part of the magic. It’s humbling. It teaches respect. Surfing isn't just a sport. It’s a state of mind. It’s patience and persistence. It’s the joy of catching your first wave or the meditative calm of floating on your board, just watching the sun dip below the horizon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d077766d-8d7b-47a1-a816-6c9b2906ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfing = \"Surfing is an experience that blends adrenaline, tranquility, and connection with nature in a way that's hard to put into words but unforgettable once you feel it. Imagine paddling out through the rhythm of the ocean, the sun warming your back, saltwater clinging to your skin. You wait just beyond the breakers, scanning the horizon for the right wave—a moment of stillness, of anticipation. When it comes, you turn your board toward shore, paddle hard, and feel the lift as the wave catches you. Then you pop up—feet planted, knees bent, arms out—and suddenly, you’re riding a force of nature. The board glides effortlessly as the wave curls behind you. There's a split second where everything aligns: your balance, the speed, the sound of rushing water, and the pure exhilaration of being carried by the ocean. Every ride is different. Some are smooth and easy, others fast and wild. Sometimes you wipe out—tossed and tumbled underwater, lungs burning, trying to find the surface. But even that feels part of the magic. It’s humbling. It teaches respect. Surfing isn't just a sport. It’s a state of mind. It’s patience and persistence. It’s the joy of catching your first wave or the meditative calm of floating on your board, just watching the sun dip below the horizon.\"\n",
    "snowboading = \"Snowboarding on fresh powder is pure freedom—like floating, flying, and dancing all at once. The moment your board hits untouched snow, everything changes. It’s soft, silent, and surreal. Instead of the usual hardpack chatter under your feet, there’s this quiet swoosh as you carve through the fluff. Each turn feels like slicing through silk. Your board sinks just a little, giving you that surfy, weightless feeling, like you're gliding above the ground. You lean back slightly to stay afloat, and with each movement, you’re not just riding the mountain—you’re flowing with it. The powder cushions every bump and fall, making the ride forgiving and playful. The world around you goes quiet—muffled by the snow—so all you hear is the wind in your ears and the sound of your own breath. Trees blur past, sunlight catches on snowflakes in the air, and your legs start to burn as you float turn after turn, not wanting it to end. It’s the kind of ride that leaves your heart pounding and your face aching from grinning so hard. The first tracks you lay through fresh powder? They’re yours alone—like signing your name on nature.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8c1c6d7-4459-4698-948f-ae684363b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Titan: 0.4042\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(surfing, 1024), generate_titan_vector_embedding(snowboading, 1024))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45e93a8e-ff31-4508-ba72-01c838b462fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Spacey: 0.9895\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_spacy_vector_embedding(surfing), generate_spacy_vector_embedding(snowboading))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c42a2dc-b367-4720-a755-baf1e5381b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Cohere: 0.7487\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(surfing), generate_cohere_vector_embedding(snowboading))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85e210-24cf-4f7d-9df8-f13f414ded7c",
   "metadata": {},
   "source": [
    "#### Random\n",
    "Okay let's try something random and see what the similarity looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d628dee7-e493-4996-8501-173cf5477220",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1= \"The giraffe wore a monocle while arguing with a squirrel about the ethics of pancake toppings.\"\n",
    "sentence2=\"A forgotten shoelace fluttered quietly on a moonlit battlefield, untouched by time or tennis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc37e034-4559-41c2-9cca-58feca7eb987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Spacey: 0.8201\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_spacy_vector_embedding(sentence1), generate_spacy_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "065178a8-a950-45e1-ac33-90ec17de76d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Titan: 0.1366\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(sentence1, 1024), generate_titan_vector_embedding(sentence2, 1024))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "baa5dbdc-0104-430d-98e9-3981d9a7fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Cohere: 0.2908\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(sentence1), generate_cohere_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c580d1-09fb-4715-9db6-d3b20533aa06",
   "metadata": {},
   "source": [
    "#### And the winner is?\n",
    "I guess it depends on what you are tryiing to accomplish.  You need to sample different embedding models based on your use case.\n",
    "Here is the [Huggingface MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c7c50-b62c-41a1-9c73-b35bbe761140",
   "metadata": {},
   "source": [
    "#### Embeddings work on images as well\n",
    "Let's compare different images together using an image embedding model.  There are many well known image embedding models here are a few:\n",
    "ResNet (e.g., ResNet-50, ResNet-101)\n",
    "-Deep residual networks\n",
    "-Common for feature extraction\n",
    "-Embeddings: vectors from the penultimate (before-softmax) layer\n",
    "VGG (VGG16, VGG19)\n",
    "-Simpler architecture\n",
    "-Good for smaller-scale tasks or transfer learning\n",
    "-Inception (GoogLeNet, Inception-v3)\n",
    "-Multi-scale filters\n",
    "-Good trade-off between speed and accuracy\n",
    "EfficientNet\n",
    "-Very efficient, scalable architecture\n",
    "-Great for resource-constrained environments\n",
    "\n",
    "Using EfficientNet let's try comparing the following images\n",
    "\n",
    "![House Sparrow](./images/sparrow-sm.jpg) ![Black Phoebe](./images/phoebe-sm.jpg) ![White Crown Sparrow](./images/whitecrown-sm.jpg)![Fork](./images/fork-sm.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fffc023-70c7-443d-aec5-57657f7e9d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load EfficientNet (without the classifier head)\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model.classifier = torch.nn.Identity()  # Remove the final classification layer\n",
    "model.eval()\n",
    "\n",
    "# Preprocessing pipeline to match EfficientNet's input requirements\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
    "        std=[0.229, 0.224, 0.225]    # ImageNet std\n",
    "    )\n",
    "])\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        embedding = model(input_tensor)\n",
    "    return embedding.squeeze()  # Remove batch dimension\n",
    "\n",
    "def cosine_similarity_torch(tensor1, tensor2):\n",
    "    return F.cosine_similarity(tensor1.unsqueeze(0), tensor2.unsqueeze(0)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e94312b-e395-4677-9b58-57ddd4812ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between two different birds: 0.3584\n",
      "Cosine similarity between the fork and the sparrow: 0.0497\n",
      "Cosine similarity between the white crown sparrow and house sparrow: 0.5262\n"
     ]
    }
   ],
   "source": [
    "# Call EfficientNet on all sample images\n",
    "fork_image_emb = get_image_embedding('./images/fork.jpg')\n",
    "sparrow_image_emb = get_image_embedding('./images/sparrow.jpg')\n",
    "phoebe_image_emb = get_image_embedding('./images/phoebe.jpg')\n",
    "white_crown_image_emb = get_image_embedding('./images/whitecrown.jpg')\n",
    "\n",
    "similarity = cosine_similarity_torch(sparrow_image_emb, phoebe_image_emb)\n",
    "print(f\"Cosine similarity between two different birds: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity_torch(sparrow_image_emb, fork_image_emb)\n",
    "print(f\"Cosine similarity between the fork and the sparrow: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity_torch(sparrow_image_emb, white_crown_image_emb)\n",
    "print(f\"Cosine similarity between the white crown sparrow and house sparrow: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50dd8b-3541-4a75-9364-2068327c792d",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "Go find some data that you think will be usefull for your project and try a few embedding models that you think mght work well for your use case.  After you manually separate the data into a few samples, show how the embedding model you choose will do a good job comaring relavancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f5a87-d2d8-44dc-9807-5da978fe254e",
   "metadata": {},
   "source": [
    "For this assignment, I explored a meal recommendation use case where a user enters a list of available ingredients and receives relevant recipes in return. My goal was to evaluate which embedding model best captures semantic similarity between the user's ingredient query and recipe descriptions. I used https://spoonacular.com/food-api for recipe data, you can sign up for a free key for 150 credits/day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20c4769d-5379-4183-8f7f-ec7f3d04ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_api_key():\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "    load_dotenv()\n",
    "    return os.getenv(\"SPOONACULAR_API_KEY\")\n",
    "\n",
    "def search_recipes_by_ingredients(ingredients, number=5):\n",
    "    api_key = get_api_key()\n",
    "    url = \"https://api.spoonacular.com/recipes/findByIngredients\"\n",
    "    params = {\n",
    "        \"ingredients\": ingredients,  # e.g. \"chicken, garlic, spinach\"\n",
    "        \"number\": number,\n",
    "        \"ranking\": 1,\n",
    "        \"ignorePantry\": True,\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "def get_recipe_summary(recipe_id):\n",
    "    api_key = get_api_key()\n",
    "    url = f\"https://api.spoonacular.com/recipes/{recipe_id}/summary\"\n",
    "    params = {\"apiKey\": api_key}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()[\"summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8a93e-bf77-4f55-b8ab-913b1800822f",
   "metadata": {},
   "source": [
    "This code defines two functions to interact with the Spoonacular API. The `search_recipes_by_ingredients()` function takes a list of ingredients and retrieves a specified number of matching recipes, while `get_recipe_summary()` fetches a natural-language summary for a specific recipe ID. I chose to compare the user’s ingredient query to each recipe’s summary because the summaries provide a natural-language description of the dish, which can capture broader contextual and semantic information that might align with the user's intent beyond exact ingredient matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4629d5f0-125b-4248-b69c-a8218412804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Chicken Dinner\n",
      "spaCy similarity:  0.7735\n",
      "Titan similarity:  0.2071\n",
      "Cohere similarity: 0.4456\n",
      "Lemon and Garlic Slow Roasted Chicken\n",
      "spaCy similarity:  0.8258\n",
      "Titan similarity:  0.4992\n",
      "Cohere similarity: 0.5940\n",
      "Flour And Water Crust Chicken\n",
      "spaCy similarity:  0.7513\n",
      "Titan similarity:  0.1345\n",
      "Cohere similarity: 0.4892\n",
      "Roast Chicken With Red Wine\n",
      "spaCy similarity:  0.7915\n",
      "Titan similarity:  0.2057\n",
      "Cohere similarity: 0.4516\n",
      "Simple Roast Chicken\n",
      "spaCy similarity:  0.7408\n",
      "Titan similarity:  0.2253\n",
      "Cohere similarity: 0.4945\n"
     ]
    }
   ],
   "source": [
    "query = \"chicken, garlic, spinach, lemon\"\n",
    "recipes = search_recipes_by_ingredients(query, number=5)\n",
    "\n",
    "query_vec_spacy = generate_spacy_vector_embedding(query)\n",
    "query_vec_titan = generate_titan_vector_embedding(query, 1024)\n",
    "query_vec_cohere = generate_cohere_vector_embedding(query)\n",
    "\n",
    "for recipe in recipes:\n",
    "    title = recipe['title']\n",
    "    summary = get_recipe_summary(recipe['id'])\n",
    "\n",
    "    # Embed the summary with all 3 models\n",
    "    vec_spacy = generate_spacy_vector_embedding(summary)\n",
    "    vec_titan = generate_titan_vector_embedding(summary, 1024)\n",
    "    vec_cohere = generate_cohere_vector_embedding(summary)\n",
    "\n",
    "    print(f\"{title}\")\n",
    "    print(f\"spaCy similarity:  {cosine_similarity(query_vec_spacy, vec_spacy):.4f}\")\n",
    "    print(f\"Titan similarity:  {cosine_similarity(query_vec_titan, vec_titan):.4f}\")\n",
    "    print(f\"Cohere similarity: {cosine_similarity(query_vec_cohere, vec_cohere):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad952e-aed1-464f-891f-37d098146f78",
   "metadata": {},
   "source": [
    "Now that we have similarity scores, let's take a look at the ingredients to see who the true winner is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0192ad5d-08cd-4169-8aa6-0feef3681ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Chicken Dinner\n",
      "Ingredients: chicken -the one here is 4.5lbs., garlic cloves, lemons, garlic, onion, broccoli, carrots, thyme, apple cider vinegar, chicken stock, potatoes, onion, veggie stock\n",
      "\n",
      "Lemon and Garlic Slow Roasted Chicken\n",
      "Ingredients: chicken weighing 2.3kg, bulbs garlic, lemons\n",
      "\n",
      "Flour And Water Crust Chicken\n",
      "Ingredients: garlic, lemons, chicken, sage, thyme\n",
      "\n",
      "Roast Chicken With Red Wine\n",
      "Ingredients: chicken, fat cloves garlic, lemon, chicken stock, onions, red wine, tarragon\n",
      "\n",
      "Simple Roast Chicken\n",
      "Ingredients: chicken, garlic, lemon, butter, rind of two lemons, chilli flakes, yukon gold potatoes, sweet potatoes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for recipe in recipes:\n",
    "    title = recipe[\"title\"]\n",
    "    \n",
    "    # Combine used and missed ingredients\n",
    "    ingredients = recipe[\"usedIngredients\"] + recipe[\"missedIngredients\"]\n",
    "    ingredient_names = [i[\"name\"] for i in ingredients]\n",
    "\n",
    "    print(f\"{title}\")\n",
    "    print(\"Ingredients:\", \", \".join(ingredient_names))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49060207-826c-425b-9b5d-96043de26aed",
   "metadata": {},
   "source": [
    "After analyzing the results from the three embedding models (spaCy, Titan, and Cohere) on a set of five recipes retrieved using the query “chicken, garlic, spinach”, it became clear that spaCy produced the most accurate and intuitive rankings. All five recipes included both chicken and garlic, but none contained spinach, which makes the ability to differentiate relevance based on partial ingredient overlap even more important. spaCy consistently assigned the highest similarity score to Lemon and Garlic Slow Roasted Chicken, a recipe that prominently features both query ingredients in its title and ingredients list. Titan, while assigning its highest score to this same recipe, produced very low scores for all others, failing to differentiate between clearly relevant and less relevant matches. Cohere fell somewhere in between; it identified some of the more relevant recipes but had a smaller spread in similarity scores, making ranking less distinct. With the ingredient lists explicitly available, I think spaCy’s rankings were well aligned with human expectations, elevating recipes that matched the user's input ingredients most closely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
